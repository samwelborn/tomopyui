{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f06e1e9e-c989-4ad4-8257-7ab9a781ba53",
   "metadata": {},
   "source": [
    "# Find Timing for Various Cupy Functions vs. Numpy Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ec775e-916a-43cd-9bf7-9ec12355b08a",
   "metadata": {},
   "source": [
    "## Set up projection image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec909fc-76b0-4c2e-81a7-92ebe0ec8f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape = (361, 1024, 1024)\n",
      "Data type = float32\n"
     ]
    }
   ],
   "source": [
    "from tomopyui.backend.io import Projections_Prenormalized\n",
    "from tomopyui.widgets.imports import PrenormUploader, Import_SSRL62C\n",
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "# setting up dummy uploader\n",
    "dummy_import = Import_SSRL62C()\n",
    "prenorm_uploader = PrenormUploader(dummy_import)\n",
    "prenorm_uploader.filedir = pathlib.Path(r\"E:\\Sam_Welborn\\20220620_Welborn\\Pristine\\all_energies\\07660.00eV\")\n",
    "json_file = prenorm_uploader.projections._file_finder(prenorm_uploader.filedir, prenorm_uploader.filetypes_to_look_for)\n",
    "prenorm_uploader.update_filechooser_from_quicksearch(json_file)\n",
    "prenorm_uploader.filepath = pathlib.Path(r\"E:\\Sam_Welborn\\20220620_Welborn\\Pristine\\all_energies\\07660.00eV\\normalized_projections.hdf5\")\n",
    "prenorm_uploader.filedir = pathlib.Path(r\"E:\\Sam_Welborn\\20220620_Welborn\\Pristine\\all_energies\\07660.00eV\")\n",
    "prenorm_uploader.filename = pathlib.Path(r\"normalized_projections.hdf5\")\n",
    "\n",
    "# Import File\n",
    "prenorm_uploader.projections.import_filedir_projections(prenorm_uploader)\n",
    "prenorm_uploader.projections._load_hdf_normalized_data_into_memory()\n",
    "print(f\"Data shape = {prenorm_uploader.projections.data.shape}\")\n",
    "print(f\"Data type = {prenorm_uploader.projections.data.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5f043b-7345-453b-b63a-b8a4649832eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b235dae4-02d5-4b11-b773-c2bae388c504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from cupyx.scipy import ndimage as ndi_cp\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import transform as tf\n",
    "import copy \n",
    "import joblib\n",
    "from time import time\n",
    "\n",
    "# Set up cupy shifting function\n",
    "def shift_prj_cp(\n",
    "    prj,\n",
    "    sx,\n",
    "    sy,\n",
    "    num_batches,\n",
    "):\n",
    "    # Why is the error calculated in such a strange way?\n",
    "    # Will use the standard used in tomopy here, but think of different way to\n",
    "    # calculate error.\n",
    "\n",
    "    num_theta = prj.shape[0]\n",
    "    err = np.zeros((num_theta + 1, 1))\n",
    "\n",
    "    # split all arrays up into batches.\n",
    "    err = np.array_split(err, num_batches)\n",
    "    prj_cpu = np.array_split(prj, num_batches, axis=0)\n",
    "    sx = np.array_split(sx, num_batches, axis=0)\n",
    "    sy = np.array_split(sy, num_batches, axis=0)\n",
    "    for batch in range(len(prj_cpu)):\n",
    "        _prj_gpu = cp.array(prj_cpu[batch], dtype=cp.float32)\n",
    "        \n",
    "        for image in range(_prj_gpu.shape[0]):\n",
    "            shift_tuple = (sy[batch][image], sx[batch][image])\n",
    "            _prj_gpu[image] = ndi_cp.shift(_prj_gpu[image], shift_tuple, order=5)\n",
    "\n",
    "        prj_cpu[batch] = cp.asnumpy(_prj_gpu)\n",
    "\n",
    "    # concatenate the final list and return\n",
    "    prj_cpu = np.concatenate(prj_cpu, axis=0)\n",
    "    err = np.concatenate(err)\n",
    "    sx = np.concatenate(sx, axis=0)\n",
    "    sy = np.concatenate(sy, axis=0)\n",
    "    return prj_cpu\n",
    "\n",
    "# Shift projections using tomopy's function (skimage), no multiprocessing\n",
    "def shift_prj_tomopy(prj, sx, sy):\n",
    "    for m in range(prj.shape[0]):\n",
    "        tform = tf.SimilarityTransform(translation=(sy[m], sx[m]))\n",
    "        prj[m] = tf.warp(prj[m], tform, order=5)\n",
    "        \n",
    "# Shift projections using tomopy's function (skimage), no multiprocessing\n",
    "def shift_prj_tomopy_mp(prj, sx, sy, m):\n",
    "        tform = tf.SimilarityTransform(translation=(sy[m], sx[m]))\n",
    "        return tf.warp(prj[m], tform, order=5)\n",
    "        \n",
    "# Shift projections using ndimage without cupy \n",
    "def shift_prj_scipy(prj, sx, sy):\n",
    "    for m in range(prj.shape[0]):\n",
    "        shift_tuple = (sy[m], sx[m])\n",
    "        prj[m] = ndi.shift(prj[m], shift_tuple, order=5)\n",
    "        \n",
    "# Shift projections using ndimage without cupy, with multiprocessing\n",
    "def shift_prj_scipy_mp(prj, sx, sy, m):\n",
    "    shift_tuple = (sy[m], sx[m])\n",
    "    return ndi.shift(prj[m], shift_tuple, order=5)\n",
    "            \n",
    "# Set up profiling function for tomopy\n",
    "def benchmark_shift_tomopy(label, prj, sx, sy, num_runs=1):\n",
    "    t = 0.0\n",
    "    for i in range(num_runs):\n",
    "        t1 = time()\n",
    "        shifted_prj = shift_prj_tomopy(prj, sx, sy)\n",
    "        t2 = time()\n",
    "        t += t2 - t1\n",
    "    t = t / num_runs\n",
    "    print(f\"{label.ljust(25)}{t:0.4f}s | avg of {num_runs} runs\")\n",
    "    return shifted_prj\n",
    "\n",
    "# Set up profiling function for numpy (scipy)\n",
    "def benchmark_shift_scipy(label, prj, sx, sy, num_runs=1):\n",
    "    t = 0.0\n",
    "    for i in range(num_runs):\n",
    "        t1 = time()\n",
    "        shifted_prj = shift_prj_scipy(prj, sx, sy)\n",
    "        t2 = time()\n",
    "        t += t2 - t1\n",
    "    t = t / num_runs\n",
    "    print(f\"{label.ljust(25)}{t:0.4f}s | avg of {num_runs} runs\")\n",
    "    return shifted_prj\n",
    "\n",
    "# Set up profiling for tomopy multiprocessing\n",
    "def benchmark_shift_tomopy_mp(label, prj, sx, sy, num_runs=1):\n",
    "    t = 0.0\n",
    "    for i in range(num_runs):\n",
    "        t1 = time()\n",
    "        result = joblib.Parallel(n_jobs=40, backend=\"threading\")(joblib.delayed(shift_prj_tomopy_mp)\n",
    "                (prj, sx, sy, m) for m in range(prj.shape[0])\n",
    "          )\n",
    "        t2 = time()\n",
    "        t += t2 - t1\n",
    "    t = t / num_runs\n",
    "    print(f\"{label.ljust(25)}{t:0.4f}s | avg of {num_runs} runs\")\n",
    "    return result\n",
    "\n",
    "# Set up profiling for scipy multiprocessing\n",
    "def benchmark_shift_scipy_mp(label, prj, sx, sy, num_runs=1):\n",
    "    t = 0.0\n",
    "    for i in range(num_runs):\n",
    "        t1 = time()\n",
    "        result = joblib.Parallel(n_jobs=40, backend=\"threading\")(joblib.delayed(shift_prj_scipy_mp)\n",
    "                (prj, sx, sy, m) for m in range(prj.shape[0])\n",
    "          )\n",
    "        t2 = time()\n",
    "        t += t2 - t1\n",
    "    t = t / num_runs\n",
    "    print(f\"{label.ljust(25)}{t:0.4f}s | avg of {num_runs} runs\")\n",
    "    return result\n",
    "\n",
    "# Set up profiling function for cupy\n",
    "def benchmark_shift_cp(label, prj, sx, sy, num_batches, num_runs=1, warm_ups=5):\n",
    "    t = 0.0\n",
    "    for i in range(warm_ups):\n",
    "        shifted_prj = shift_prj_cp(prj, sx, sy, num_batches)\n",
    "        cp.cuda.stream.get_current_stream().synchronize()\n",
    "    for i in range(num_runs):\n",
    "        t1 = time()\n",
    "        shifted_prj = shift_prj_cp(prj, sx, sy, num_batches)\n",
    "        cp.cuda.stream.get_current_stream().synchronize()\n",
    "        t2 = time()\n",
    "        t += t2 - t1\n",
    "    t = t / num_runs\n",
    "    print(f\"{label.ljust(25)}{t:0.4f}s | average of {num_runs} runs\")\n",
    "    return shifted_prj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63fb2db-1c0e-481c-a6d4-0b50e10a04f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure downsampled data not loaded\n",
    "prenorm_uploader.projections._load_hdf_normalized_data_into_memory()\n",
    "\n",
    "# Generate random shifts\n",
    "shift_x = np.random.rand(361) * 30\n",
    "shift_y = np.random.rand(361) * 30\n",
    "\n",
    "num_runs = 10\n",
    "num_batches = 1 # for cutting data up\n",
    "\n",
    "# Tomopy benchmark\n",
    "prj = np.array(copy.deepcopy(prenorm_uploader.projections.data))\n",
    "benchmark_shift_tomopy(f\"tomopy (skimage.transform.warp): \", prj, shift_x, shift_y, num_runs=num_runs)\n",
    "\n",
    "# Tomopy benchmark with parallel\n",
    "prj = np.array(copy.deepcopy(prenorm_uploader.projections.data))\n",
    "benchmark_shift_tomopy_mp(f\"tomopy (skimage.transform.warp) with multiprocessing: \", prj, shift_x, shift_y, num_runs=num_runs)\n",
    "\n",
    "# Scipy benchmark\n",
    "prj = np.array(copy.deepcopy(prenorm_uploader.projections.data))\n",
    "benchmark_shift_scipy(f\"scipy.ndimage.shift: \", prj, shift_x, shift_y, num_runs=num_runs)\n",
    "\n",
    "# Scipy benchmark with parallel\n",
    "prj = np.array(copy.deepcopy(prenorm_uploader.projections.data))\n",
    "benchmark_shift_scipy_mp(f\"scipy.ndimage.shift with multiprocessing: \", prj, shift_x, shift_y, num_runs=num_runs)\n",
    "\n",
    "# Scipy-cupy benchmark with parallel\n",
    "prj = np.array(copy.deepcopy(prenorm_uploader.projections.data))\n",
    "benchmark_shift_cp(f\"cupyx.scipy.ndimage.shift: \", prj, shift_x, shift_y, num_batches, num_runs=num_runs)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffc16c4-36c5-44df-b001-7c536abdb46b",
   "metadata": {},
   "source": [
    "## Phase cross correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc42f1b7-cf0f-4025-9b9d-80188f192c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.registration import phase_cross_correlation as phase_cross_correlation_tomopy\n",
    "from tomopyui.backend.util.registration._phase_cross_correlation_cupy import phase_cross_correlation as phase_cross_correlation_cp\n",
    "\n",
    "def pcc_tomopy(prj, sim, upsample_factor):\n",
    "    for m in range(prj.shape[0]):\n",
    "        phase_cross_correlation_tomopy(prj[m], sim[m], upsample_factor=upsample_factor, return_error=False)\n",
    "\n",
    "def pcc_tomopy_mp(prj, sim, upsample_factor, m):\n",
    "    return phase_cross_correlation_tomopy(prj[m], sim[m], upsample_factor=upsample_factor, return_error=False)\n",
    "\n",
    "def pcc_cp(prj, sim, upsample_factor, num_batches):\n",
    "    _prj = np.array_split(prj, num_batches, axis=0)\n",
    "    _sim = np.array_split(sim, num_batches, axis=0)\n",
    "    shift_cpu = []\n",
    "    for batch in range(len(_prj)):\n",
    "        _prj_gpu = cp.array(_prj[batch], dtype=cp.float32)\n",
    "        _sim_gpu = cp.array(_sim[batch], dtype=cp.float32)\n",
    "        shift_gpu = phase_cross_correlation_cp(\n",
    "            _sim_gpu,\n",
    "            _prj_gpu,\n",
    "            upsample_factor=upsample_factor,\n",
    "            return_error=False,\n",
    "        )\n",
    "        shift_cpu.append(cp.asnumpy(shift_gpu))\n",
    "    shift_cpu = np.concatenate(shift_cpu, axis=1)\n",
    "    return shift_cpu\n",
    "    \n",
    "# Set up profiling function for tomopy's processing\n",
    "def benchmark_pcc_tomopy(label, prj, sim, upsample_factor, num_runs=1):\n",
    "    t = 0.0\n",
    "    for i in range(num_runs):\n",
    "        t1 = time()\n",
    "        pcc_tomopy(prj, sim, upsample_factor)\n",
    "        t2 = time()\n",
    "        t += t2 - t1\n",
    "    t = t / num_runs\n",
    "    print(f\"{label.ljust(50)}{t:0.4f}s | avg of {num_runs} runs\")\n",
    "\n",
    "# Set up profiling for tomopy multiprocessing\n",
    "def benchmark_pcc_tomopy_mp(label, prj, sim, upsample_factor, num_runs=1):\n",
    "    t = 0.0\n",
    "    for i in range(num_runs):\n",
    "        t1 = time()\n",
    "        result = joblib.Parallel(n_jobs=40, backend=\"threading\")(joblib.delayed(pcc_tomopy_mp)\n",
    "                (prj, sim, upsample_factor, m) for m in range(prj.shape[0])\n",
    "          )\n",
    "        t2 = time()\n",
    "        t += t2 - t1\n",
    "    t = t / num_runs\n",
    "    print(f\"{label.ljust(50)}{t:0.4f}s | avg of {num_runs} runs\")\n",
    "    return result\n",
    "\n",
    "\n",
    "# Set up profiling function for cupy\n",
    "def benchmark_pcc_cp(label, prj, sim, upsample_factor, num_batches, num_runs=1, warm_ups=1):\n",
    "    t = 0.0\n",
    "    for i in range(warm_ups):\n",
    "        pcc_cp(prj, sim, upsample_factor, num_batches)\n",
    "    for i in range(num_runs):\n",
    "        t1 = time()\n",
    "        pcc_cp(prj, sim, upsample_factor, num_batches)\n",
    "        cp.cuda.stream.get_current_stream().synchronize()\n",
    "        t2 = time()\n",
    "        mempool = cp.get_default_memory_pool()\n",
    "        mempool.free_all_blocks()\n",
    "        t += t2 - t1\n",
    "    t = t / num_runs\n",
    "    print(f\"{label.ljust(50)}{t:0.4f}s | average of {num_runs} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37140b58-0b16-45bb-affd-3b7606ff72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random shifts\n",
    "shift_x = np.random.rand(361) * 30\n",
    "shift_y = np.random.rand(361) * 30\n",
    "prj = np.array(copy.deepcopy(prenorm_uploader.projections.data))\n",
    "sim = joblib.Parallel(n_jobs=40, backend=\"threading\")(joblib.delayed(shift_prj_tomopy_mp)\n",
    "        (prj, shift_x, shift_y, m) for m in range(prj.shape[0])\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc790224-a395-4af4-be2c-e8d7645052ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cupy PCC:                                         4.6431s | average of 10 runs\n",
      "Tomopy PCC with multiprocessing:                  7.2724s | avg of 10 runs\n",
      "Tomopy PCC without multiprocessing:               53.5911s | avg of 10 runs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.fft\n",
    "\n",
    "# Make sure downsampled data not loaded\n",
    "prenorm_uploader.projections._load_hdf_normalized_data_into_memory()\n",
    "\n",
    "num_runs = 10\n",
    "num_batches = 4 # for cutting data up\n",
    "upsample_factor = 50\n",
    "mempool = cp.get_default_memory_pool()\n",
    "mempool.free_all_blocks()\n",
    "\n",
    "# # Cupy benchmark\n",
    "prj = np.array(copy.deepcopy(prenorm_uploader.projections.data))\n",
    "benchmark_pcc_cp(f\"Cupy PCC: \", prj, sim, upsample_factor, num_batches, num_runs=num_runs, warm_ups=5)\n",
    "\n",
    "# Tomopy benchmark with multithreading\n",
    "scipy.fft.set_global_backend(\"scipy\")\n",
    "prj = np.array(copy.deepcopy(prenorm_uploader.projections.data))\n",
    "benchmark_pcc_tomopy_mp(f\"Tomopy PCC with multiprocessing: \", prj, sim, upsample_factor, num_runs=num_runs)\n",
    "\n",
    "# Tomopy benchmark\n",
    "scipy.fft.set_global_backend(\"scipy\")\n",
    "prj = np.array(copy.deepcopy(prenorm_uploader.projections.data))\n",
    "benchmark_pcc_tomopy(f\"Tomopy PCC without multiprocessing: \", prj, sim, upsample_factor, num_runs=num_runs)\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14644a9e-ca61-4388-8516-ba21128a72ab",
   "metadata": {},
   "source": [
    "## Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38a41e92-d7d9-49c7-b42f-a59ff0f4c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomopyui.tomocupy.recon.algorithm as tomocupy_algorithm\n",
    "from tomopyui.tomocupy.prep.alignment import simulate_projections as simulate_projections_3D\n",
    "from tomopy.sim.project import project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "787462af-c353-45ef-aa6e-e0a165baba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_simulate_astra(label, rec, num_batches, num_runs=1):\n",
    "    t = 0.0\n",
    "    for i in range(num_runs):\n",
    "        t1 = time()\n",
    "        _rec = np.array_split(rec, num_batches, axis=0)\n",
    "        sim = []\n",
    "        simulate_projections_3D(\n",
    "            _rec,\n",
    "            sim,\n",
    "            center,\n",
    "            theta\n",
    "        )\n",
    "        sim = np.concatenate(sim, axis=1)\n",
    "        t2 = time()\n",
    "        t += t2 - t1\n",
    "    t = t / num_runs\n",
    "    print(f\"{label.ljust(50)}{t:0.4f}s | avg of {num_runs} runs\")\n",
    "    \n",
    "def benchmark_simulate_tomopy(label, rec, num_runs=1):\n",
    "    t = 0.0\n",
    "    for i in range(num_runs):\n",
    "        t1 = time()\n",
    "        sim = project(rec, theta, pad=False)\n",
    "        t2 = time()\n",
    "        t += t2 - t1\n",
    "    t = t / num_runs\n",
    "    print(f\"{label.ljust(50)}{t:0.4f}s | avg of {num_runs} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a0b1d81-15d1-4e38-a2a5-fbb7a265ffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomopy Projection with Multithreading:            24.1174s | avg of 10 runs\n",
      "3D Astra Projection:                              0.1626s | avg of 10 runs\n"
     ]
    }
   ],
   "source": [
    "# Loading half downsampled data into memory\n",
    "prenorm_uploader.projections._load_hdf_ds_data_into_memory(pyramid_level=2)\n",
    "prj = copy.deepcopy(prenorm_uploader.projections.data_ds)\n",
    "theta = prenorm_uploader.projections.angles_rad\n",
    "center = prj.shape[1] / 2\n",
    "num_runs = 10\n",
    "rec = tomocupy_algorithm.recon_sirt_3D(\n",
    "    prj,\n",
    "    theta,\n",
    "    num_iter=1,\n",
    "    center=center,\n",
    ")\n",
    "\n",
    "# Tomopy multiprocessing projection\n",
    "benchmark_simulate_tomopy(f\"Tomopy Projection with Multithreading: \", rec, num_runs=num_runs)\n",
    "\n",
    "# Astra 3D projection\n",
    "num_batches = 5\n",
    "benchmark_simulate_astra(f\"3D Astra Projection: \", rec, num_batches=num_batches, num_runs=num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf59d23-1ba1-4a5a-a50d-63087f5dc158",
   "metadata": {},
   "source": [
    "## Reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec766cdc-d86e-4a57-985b-d46e1eb1397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomopy.recon as tomopy_algorithm\n",
    "from tomopy.recon import wrappers\n",
    "\n",
    "def benchmark_recon_astra3d(label, rec, recon_iter, num_runs=1):\n",
    "    t = 0.0\n",
    "    for i in range(num_runs):\n",
    "        t1 = time()\n",
    "        rec = tomocupy_algorithm.recon_sirt_3D(\n",
    "            prj,\n",
    "            theta,\n",
    "            num_iter=recon_iter,\n",
    "            center=center,\n",
    "        )\n",
    "        t2 = time()\n",
    "        t += t2 - t1\n",
    "    t = t / num_runs\n",
    "    print(f\"{label.ljust(50)}{t:0.4f}s | avg of {num_runs} runs\")\n",
    "    \n",
    "def benchmark_recon_astra_plugin(label, rec, recon_iter, num_runs=1):\n",
    "    t = 0.0\n",
    "    for i in range(num_runs):\n",
    "        t1 = time()\n",
    "        rec = tomocupy_algorithm.recon_sirt_plugin(\n",
    "            prj,\n",
    "            theta,\n",
    "            num_iter=recon_iter,\n",
    "            center=center,\n",
    "        )\n",
    "        t2 = time()\n",
    "        t += t2 - t1\n",
    "    t = t / num_runs\n",
    "    print(f\"{label.ljust(50)}{t:0.4f}s | avg of {num_runs} runs\")\n",
    "    \n",
    "def benchmark_recon_tomopy_astra(label, rec, recon_iter, num_runs=1):\n",
    "    t = 0.0\n",
    "    for i in range(num_runs):\n",
    "        kwargs = {}\n",
    "        options = {\n",
    "            \"proj_type\": \"cuda\",\n",
    "            \"method\": \"SIRT_CUDA\",\n",
    "            \"num_iter\": recon_iter,\n",
    "        }\n",
    "        kwargs[\"options\"] = options\n",
    "        t1 = time()\n",
    "        rec = tomopy_algorithm(\n",
    "                    prj,\n",
    "                    theta,\n",
    "                    algorithm=wrappers.astra,\n",
    "                    center=center,\n",
    "                    ncore=1,\n",
    "                    **kwargs,\n",
    "                )\n",
    "        t2 = time()\n",
    "        t += t2 - t1\n",
    "    t = t / num_runs\n",
    "    print(f\"{label.ljust(50)}{t:0.4f}s | avg of {num_runs} runs\")\n",
    "    \n",
    "def benchmark_recon_tomopy(label, rec, recon_iter, num_runs=1):\n",
    "    t = 0.0\n",
    "    for i in range(num_runs):\n",
    "        t1 = time()\n",
    "        rec = tomopy_algorithm(\n",
    "                    prj,\n",
    "                    theta,\n",
    "                    algorithm=\"sirt\",\n",
    "                    center=center,\n",
    "                    ncore=40,\n",
    "                )\n",
    "        t2 = time()\n",
    "        t += t2 - t1\n",
    "    t = t / num_runs\n",
    "    print(f\"{label.ljust(50)}{t:0.4f}s | avg of {num_runs} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da2f61ac-2005-4111-af6d-132007179588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIRT - Astra 3D:                                  3.1805s | avg of 10 runs\n",
      "SIRT - Astra Plugin:                              5.5297s | avg of 10 runs\n",
      "SIRT - Tomopy Astra Wrapper:                      14.9786s | avg of 10 runs\n",
      "SIRT - Tomopy CPU:                                50.6492s | avg of 10 runs\n"
     ]
    }
   ],
   "source": [
    "# Loading half downsampled data into memory\n",
    "prenorm_uploader.projections._load_hdf_ds_data_into_memory(pyramid_level=0)\n",
    "prj = copy.deepcopy(prenorm_uploader.projections.data_ds)\n",
    "theta = prenorm_uploader.projections.angles_rad\n",
    "center = prj.shape[1] / 2\n",
    "recon_iter = 1\n",
    "num_runs = 10\n",
    "\n",
    "benchmark_recon_astra3d(f\"SIRT - Astra 3D: \", prj, recon_iter, num_runs=num_runs)\n",
    "\n",
    "benchmark_recon_astra_plugin(f\"SIRT - Astra Plugin: \", prj, recon_iter, num_runs=num_runs)\n",
    "\n",
    "benchmark_recon_tomopy_astra(f\"SIRT - Tomopy Astra Wrapper: \", prj, recon_iter, num_runs=num_runs)\n",
    "\n",
    "benchmark_recon_tomopy(f\"SIRT - Tomopy CPU: \", prj, recon_iter, num_runs=num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d11e85-1aad-42ea-85dc-eaf896b121c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
